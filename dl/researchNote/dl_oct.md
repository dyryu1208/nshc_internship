# 목차

* [2021.10.05](#anchor-20211005)
* [2021.10.06 ~ 2021.10.08](#anchor-20211006)
* [2021.10.12 ~ 2021.10.13](#anchor-20211012)
* [2021.10.14 ~ 2021.10.15](#anchor-20211014)
* [2021.10.19 ~ 2021.10.20](#anchor-20211019)
* [2021.10.29](#anchor-20211029)


# 2021.10.05
#### ES의 문제점
1. 우리가 원하는 광범위한 정보들을 단 하나의 쿼리문만으로 가져오기는 역부족
2. 새로 수집한 데이터를 자동적으로 분류하는 기능은 ES에는 탑재되어 있지 않음

#### 새로운 접근법 필요
* 머신러닝/딥러닝을 활용하여 html데이터들을 학습한 뒤, 새로 들어오는 데이터들을 카테고리별로 분류할수 있게 하는 모델 생성
    * 텍스트분류에 사용되는 머신러닝/딥러닝 알고리즘에 대한 정보조사
      * Tensorflow의 Keras 모듈 중 Embedding / LSTM / GRU 3개를 적용하기로 결정
* 참고자료 : 
  * <https://wikidocs.net/24873>  
  * <https://wikidocs.net/22933> 
  * <https://wikidocs.net/21698>


# 2021.10.06
* Keras 모듈 관련 정보조사 및 샘플코드 학습 완료
* WinSCP로 가져온 cralwer_v4 파일들 중 몇 개를 모델이 학습할 데이터셋으로 선정
* **1차 테스트**
* 가져온 데이터를 성범죄 유무(성범죄: 1, 성범죄X: 0)를 판단하는 분류분석 모델 생성
  * html 전처리 및 데이터 라벨링 작업 수행이 우선!


# 2021.10.08
* 기존 모델에 약간의 옵션 조정 테스트
  * optimizer를 adam으로 변경 / 반복 학습 횟수 및 학습횟수 증대(epochs, learning_rate) 
      * 학습 데이터 검증기준 약 98%로 정확도 크게 향상


# 2021.10.12
* **문제점** 
* ①	98%의 정확도를 보인 결과는 train 데이터에서 같이 전처리해준 데이터의 정확도
  * 새로운 데이터를 접했을 때(test데이터셋) 정확도가 높아야 프로젝트 목표에 부합
* ②	800개 데이터는 학습에 적당한 양이 아닐 뿐더러, 데이터 라벨링작업 도중 그 내용이 편향되어 있음을 확인(특정 커뮤니티에서 파생된 글이 대부분)

* **2차 테스트**
* 팀장님이 보내주신 onion-share-link 데이터(WinSCP와는 다른 html데이터)로 모델 정확도 체크
* 모델학습용 데이터 수를 최소 2배 이상 늘릴 것!
* test데이터셋 만들고, 라벨링 작업 실시할 것!

# 2021.10.13
## 위 테스트 코드는 test_2.ipynb 파일에 존재
* 84개의 html과 라벨링이 포함된 test데이터셋을 생성했고, train데이터셋도 약 1600개로 늘린 뒤 1차 테스트에서 생성한 모델에 적용
    * 약 54%의 예측률을 보였으며, 실제 정답값과 비교했을 때 사실상 답을 찍은 수준과 다름없음
    * (대부분의 데이터를 0이라고 예측)

# 2021.10.14
* **2차 테스트 문제점**
* ①	train 데이터중 성범죄와 관련된 데이터는 너무 편향되어 있었음(특정 커뮤니티 파생 글이 다수)
* ②	Tokenizer.word_index로 단어 출현 빈도수 랭킹을 체크해보니, 일본어/러시아어와 같은 Non-English단어들이 상위 랭킹을 차지하고 있었음
    * <img src="/uploads/00281b1483329228d22910c4ec958e5a/image.png" />
  
* **3차 테스트**
* Datasetmaking 파일의 html필드뿐 아니라 path필드에도 중복제거 로직을 주어 데이터 편향성 축소
* 중복을 더 준 만큼 WinSCP에서 추가로 파일 로드
* Non-English를 제거하는 전처리코드 생성
* 학습할 단어수 제한(너무 많은 단어를 학습해버리면 과적합화 예상) => 팀장님 피드백으로 일단은 제한을 두지 않음


# 2021.10.15
## Non-English 제거작업

Nltk의 word 모듈 다운 후 정규식으로 통화기호($) 제외한 모든 특수문자 제거하는 로직 생성


    nltk.download("words")
    words = set(nltk.corpus.words.words())
    processed_html = []
    for num in range(1561):
    a = input[num]
    if "$" in a :                                 
        sent = re.sub("[^a-zA-z0-9$]"," ",a) 
    edit = " ".join(w for w in nltk.wordpunct_tokenize(sent) \
                if w.lower() in words or not w.isalpha())
        processed_html.append(edit)
    else : 
        sent = re.sub("[^a-zA-z0-9]"," ",a)
        edit_2 = " ".join(w for w in nltk.wordpunct_tokenize(sent) \
                if w.lower() in words or not w.isalpha())
        processed_html.append(edit_2)
    len(processed_html)


Nltk의 stopwords 모듈을 사용하여 the, a, me, it 등의 불용어를 제거하는 로직 생성 
- 약 179개의 영어 불용어 제거


# 2021.10.19
## 관련 테스트 코드는 test_3.ipynb 파일에 존재
* **3차 테스트결과**
1. 모델 정확도 
   1. Embedding(RNN) 모델: 56%
   2. LSTM 모델: 66%
   3. GRU 모델: 66%

* 한계점: test데이터셋의 수가 매우 적었고, 성범죄 label(1) 개수는 4개에 불과
* 또한, model.predict(test_seq) 시 제대로 맞춘 것이 거의 없음을 확인(대체로 0으로 찍어 정답을 맞춘 케이스)

## 수동 라벨링의 한계가 있으므로 분류기준 재정립 논의필요
* 카테고리 수를 늘릴지(다중 분류) 이진분류 유지할지 선택
  * 다중분류시 각 카테고리 분류기준에 대한 부가설명파일 필요
* StratifiedKFold 기법 사용여부 결정
* 중복 로직을 적용했음에도 남아있는 중복은 어떻게 해야하나?


# 2021.10.20
* **팀장님 피드백**
* ① 성범죄 유무를 따지기엔 라벨링 비율이 편향되어 있어 기준 재정립 실시
  * 범죄인지(1) 아닌지(0) 구분하는 라벨링 작업 실시
  * 이후 4차 테스트가 효과적이라면 범죄(1)에서 카테고리 가지를 늘리는 걸로!
* ② 중복제거 로직을 따로 두기보다는 dataset_making에서 경로 중 main html들만 긁어오기!
  * 거기서도 중복이 발생하겠지만 그 데이터들은 안고 가는 걸로!
* ③ Ahmia.fi(onion-share-link)에서 가져오는 데이터를 최대한 늘려서 라벨링까지완료!
  * (DeadLine : 22일까지)
* ④ RandomForest,DecisionTree,CatBoost 등 ML활용 방안도 추가적으로 검토


# 2021.10.29
## 위 날짜부터는 test_4.ipynb 파일에 작업
## 4차 테스트 전처리 이슈
* $ 전처리에 대해 작업했으나, 정작 tokenizer() 모듈에서 특수기호들 전부 제거하는것 확인
* 데이터 전처리 도중 숫자를 남겨두는 것이 의미가 있는가?
## 각 숫자들의 의미를 확인해 보기로 결정
* **조사 결과**
* 1) 숫자 자리수가 5자리(만 단위)이하 
  * 주로 번호/금액/연도/상품재고수/나이/고객수 등과 관련된 숫자
* 2) 숫자 자리수 5자리 초과
  * a. ZIP(주소코드)
  * b. 카드 및 계정번호
  * c. 각 사이트의 Views / Posts / Hits 와 같은 정보
  * d. 시간정보 띄어쓰기 오류 : 192021 / 202020 / 112021 …..
    * ex. 00:00:192021-01-06 => 00:00:19  2021-01-06 이 맞음
  * e. url에서 나온 숫자 ex. https://tools.cisco.com/security/center/…rtId=42703
* 3) 숫자와 영어가 붙어있는경우(ex. Germanyperosonal2189) 
  * 크롤링 과정에서 제대로 띄어쓰기가 안 된 것으로 보임(해결불가?)
  * 이 뿐만 아니라 영단어 중에서도 productpricequantity 처럼 제대로 띄어쓰기가 안된 것들 확인 
* 4) 비트코인기호 관련오류
  * 비트코인이 0.00328536btc 이런식으로 되어있는 애들은 소수점과 앞의 0을 지운 후 00328536btc 와 같은 형태로 남아있는 것 확인
  * 단, 0.005984 BTC처럼 중간에 띄어쓰기가 있는 경우에는 0.005984와 BTC를 별개의 단어로 보고 숫자를 0.005984 --> 5984로 변형하여 인식하는 것 확인
  * (이는 $표기에서도 동일하게 나타남)
  * BTC2167 
    * 원래는 0.3BTC 2167$(0.3BTC는 2167불) 이 맞는데 띄어쓰기 오류로 인해 (3, BTC2167)  2가지만 나오는 현상발생
