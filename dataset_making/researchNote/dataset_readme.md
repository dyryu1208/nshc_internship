# 목차
### dl 폴더의 test_2,test_3 등의 파일과 연계하여 작업했으므로 
### 정보조사 및 데이터 양에 따른 모델 예측결과 또한 Note에 포함
* [2021.10.06](#anchor-20211006)
* [2021.10.07](#anchor-20211007)
* [2021.10.12](#anchor-20211012)
* [2021.10.13](#anchor-20211013)
* [2021.10.14](#anchor-20211014)
* [2021.10.18](#anchor-20211018)
* [2021.10.20](#anchor-20211020)
* [2021.10.21 ~ 2021.10.28](#anchor-20211021)


# 2021.10.06
* Keras 모듈 관련 정보조사 완료
* WinSCP로 가져온 cralwer_v4 파일들 중 몇 개를 모델이 학습할 데이터셋으로 선정

**1차테스트**
- 가져온 데이터를 성범죄 유무(성범죄: 1, 성범죄X: 0  이라고 표시)를 판단하는 분류분석 모델 생성)
    - html 전처리 및 데이터 라벨링 작업수행이 우선적으로 수행되어야!


# 2021.10.07
* 800개 정도의 데이터를 라벨링 완료
* 테스터용 모델을 Google Colab 툴로 제작 및 테스트 수행
* 800개 데이터를 대상으로 DL 테스트 결과 50%를 조금 넘는 정확도(Accuracy)를 보였음


# 2021.10.12
1. 이전 테스트의 문제점:
    1. 98%의 정확도는 학습용데이터 내에서 같이 전처리 한 데이터에 대한 검증결과
    *  결국 Unseen 데이터에 대한 정확도가 높아야 프로젝트 목표에 부합하는 분류모델
    3. 800개의 데이터는 학습에 적당한 양이 아님(최소 1500개 이상의 데이터 필요!) 
    4. 수집한 데이터 라벨링 작업 도중 데이터가 편향되어 있음을 확인
    * ex. 특정 커뮤니티에서 파생되어 나온 글들


**2차 테스트**
* 팀장님이 추가로 보내주신 onion-share-link에 들어있는 데이터(WinSCP와는 약간 다른 html데이터)로 모델 정확도 체크

* 추가로, 모델이 학습할 데이터수를 최소 2배 이상 늘릴 것!
    * (결국, 새로 받은 데이터들에 대해서도 라벨링 작업 필요...)


# 2021.10.13
* 약 84개의 새로운 test 데이터셋을 라벨링했고, train 데이터셋도 약 1600개로 늘린 후 
* **1차 테스트**에서 생성한 모델에 적용
* 약 54%의 예측률을 보였으며, 실제 정답값과 비교시 사실상 모델이 답을 찍은 수준과 다름없음(대부분의 데이터를 성범죄가 아니라고 예측)


# 2021.10.14
#### 2차 테스트의 예측률 관련 문제점
1. 모델이 학습했던 데이터 중 성범죄와 관련된 데이터는 너무 편향 및 파생되어 있었음
* (특정 커뮤니티에서 나온 글이 다수)
2. Tokenizer.word_index로 단어 출현 빈도수 랭크를 체크해보니, 일본어/러시아어 같은 Non-English들이 상위 랭크를 차지 

**3차 테스트**
* train 데이터셋의 html필드 뿐 아니라 path필드에도 중복제거 로직을 주어 데이터 편향성 축소
* 중복을 더 제거한 만큼 WinSCP에서 추가로 파일 로드
* Non-English를 제거하고 모델이 학습하게 하는 로직 생성
* 학습할 단어수 제한(너무 많은 단어 학습시 과적합화 예상) --> 팀장님 피드백으로 일단은 제한을 두지 않음


# 2021.10.18
* WinSCP에서 더 많은 데이터를 받아와 html & path 필드의 중복제거 후, 데이터 라벨링 수행
* Onion-share-link(test 데이터)숫자도 더 늘려주는 작업 수행


# 2021.10.20

**팀장님 피드백**
1. 성범죄 / 성범죄X 를 따지기엔 성범죄 데이터 비율이 너무 적어 기준 재정립 필요
2. 중복제거 로직을 따로 두기보다는 데이터셋 만들때 경로 중 main html들만 긁어오는 로직 추가!
* main html에서 가져온 데이터도 중복이 있겠으나 그들은 안고 가는걸로!
3. onion-share-link에서 가져온 데이터 수를 최대한 늘려 라벨링까지 수행
4. RandomForest,DecisionTree,Catboost 등의 머신러닝 모델로 텍스트 분류방안 확인


**4차 테스트**
1. 이진분류(범죄 / 범죄X)로 기준 변경
2. train / test 데이터셋 크기 더 증대
3. 중복 관련 이슈는 팀장님 피드백 참고하여 해결
4. 정규식을 활용한 특수문자 전처리
    4. 달러표시 및 마침표를 살리는 정규식 구문 확인


# 2021.10.21 ~ 2021.10.28

### 2021.10.21
* 데이터 라벨링 작업수행
* 팀장님이 이전 연구자료파일(txt) 주셨음 --> test데이터셋 또는 관련 폴더에 추가하는 작업 수행

### 2021.10.22
* 1030번부터 중복제거 및 라벨링 수행
    * 수동 중복제거 했더니 약 2500개 데이터 남음
    * --> test 데이터로 사용

### 2021.10.23
* 라벨링 수동작업 실시
* 2500개 중 약 1100개 수행


### 2021.10.25
* Excel 파일 오류 발생으로 데이터 정리 후 작업 재실시 
    * 2500개 중 1100개 수행


### 2021.10.26
* 라벨링 수동작업 완료
* 라벨링 분포 체크시 범죄와 범죄X의 비율이 거의 1:1
    * 이 데이터를 train 데이터로 결정(train_data.csv)


### 2021.10.27 ~ 2021.10.28
* Test 데이터 관련 추가 라벨링 작업 완료 및 데이터셋 생성(test_data.csv)




